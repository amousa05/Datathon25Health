{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c6629c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HQO hospitals: 126\n",
      "MOH locations: 231\n",
      "Merged rows: 126\n",
      "MATCH_METHOD\n",
      "auto      109\n",
      "manual     17\n",
      "Name: count, dtype: int64\n",
      "Saved hospital_ed_merged_with_geo.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# -----------------------------------------\n",
    "# 1. Paths\n",
    "# -----------------------------------------\n",
    "hq_path  = \"hqontario_ed_all_metrics.csv\"\n",
    "geo_path = \"Ministry_of_Health_Hospitals_Geo.csv\"\n",
    "\n",
    "hq  = pd.read_csv(hq_path)   # has HOSPITAL + ED metrics\n",
    "geo = pd.read_csv(geo_path)  # has ENGLISH_NAME, LONGITUDE, LATITUDE, ADDRESS, SERVICE_TYPE, ...\n",
    "\n",
    "print(\"HQO hospitals:\", len(hq))\n",
    "print(\"MOH locations:\", len(geo))\n",
    "\n",
    "# -----------------------------------------\n",
    "# 2. Normalization helper\n",
    "# -----------------------------------------\n",
    "def normalize(name: str) -> str:\n",
    "    if not isinstance(name, str):\n",
    "        return \"\"\n",
    "    s = name.upper()\n",
    "    s = re.sub(r\"[^A-Z0-9]+\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "hq[\"norm\"]  = hq[\"HOSPITAL\"].apply(normalize)\n",
    "geo[\"norm\"] = geo[\"ENGLISH_NAME\"].apply(normalize)\n",
    "\n",
    "# -----------------------------------------\n",
    "# 3. Manual override mapping (17 tricky ones)\n",
    "#    KEY:  HOSPITAL (from HQ file)\n",
    "#    VAL:  ENGLISH_NAME (from MOH geo file)\n",
    "# -----------------------------------------\n",
    "manual_map = {\n",
    "    \"Mackenzie Health-Jane Street Site\":\n",
    "        \"MacKenzie Health - Cortellucci Vaughan Hospital\",\n",
    "\n",
    "    \"Brightshores Health System-Lions Head Site\":\n",
    "        \"Grey Bruce Health Services - Lion's Head\",\n",
    "\n",
    "    \"Brightshores Health System-Meaford Site\":\n",
    "        \"Grey Bruce Health Services - Meaford\",\n",
    "\n",
    "    \"St. Joseph's Health Care System-Hamilton\":\n",
    "        \"St. Joseph's Healthcare Hamilton - Charlton Campus\",\n",
    "\n",
    "    \"Bluewater Health-Charlotte Eleanor Englehart (Petrolia)\":\n",
    "        \"Bluewater Health - Petrolia\",\n",
    "\n",
    "    \"Scarborough Health Network-Scar.Gen.Site\":\n",
    "        \"Scarborough Health Network - Scarborough General\",\n",
    "\n",
    "    \"Brightshores Health System-Markdale Site\":\n",
    "        \"Grey Bruce Health Services - Markdale\",\n",
    "\n",
    "    \"Brightshores Health System-Wiarton Site\":\n",
    "        \"Grey Bruce Health Services - Wiarton\",\n",
    "\n",
    "    # Sinai Health System: MOH dataset only has Hennick Bridgepoint,\n",
    "    # so we map to that to at least get a Toronto coordinate.\n",
    "    \"Sinai Health System-Mount Sinai Site\":\n",
    "        \"Hennick Bridgepoint Hospital\",\n",
    "\n",
    "    \"Quinte Health - Bancroft\":\n",
    "        \"Quinte Health - North Hastings\",\n",
    "\n",
    "    \"Brightshores Health System-Southampton Site\":\n",
    "        \"Grey Bruce Health Services - Southampton\",\n",
    "\n",
    "    \"University Health Network-General Site\":\n",
    "        \"University Health Network - Toronto General\",\n",
    "\n",
    "    \"Health Sciences North-Laurentian\":\n",
    "        \"Health Sciences North - Ramsay Lake Health Centre\",\n",
    "\n",
    "    \"Perth & Smiths Falls Dist-Smiths Falls Site\":\n",
    "        \"Perth and Smiths Falls District Hospital - Smiths Falls\",\n",
    "\n",
    "    \"Brightshores Health System-Owen Sound\":\n",
    "        \"Grey Bruce Health Services - Owen Sound\",\n",
    "\n",
    "    \"Grand River Hospital Corp-Waterloo Site\":\n",
    "        \"Grand River Hospital - Kitchener-Waterloo\",\n",
    "\n",
    "    \"Sault Area Hospital-Sault Ste. Marie\":\n",
    "        \"Sault Area Hospital - General Site\",\n",
    "}\n",
    "\n",
    "# sanity check: all manual keys exist in HQ\n",
    "missing_manual_keys = set(manual_map.keys()) - set(hq[\"HOSPITAL\"])\n",
    "if missing_manual_keys:\n",
    "    print(\"Warning: these manual_map keys not found in HQ file:\", missing_manual_keys)\n",
    "\n",
    "# -----------------------------------------\n",
    "# 4. Build full merge: manual first, fuzzy fallback\n",
    "# -----------------------------------------\n",
    "def build_full_merge(hq_df, geo_df, manual):\n",
    "    hq_df = hq_df.copy()\n",
    "    geo_df = geo_df.copy()\n",
    "\n",
    "    # Ensure norm columns exist\n",
    "    if \"norm\" not in hq_df:\n",
    "        hq_df[\"norm\"] = hq_df[\"HOSPITAL\"].apply(normalize)\n",
    "    if \"norm\" not in geo_df:\n",
    "        geo_df[\"norm\"] = geo_df[\"ENGLISH_NAME\"].apply(normalize)\n",
    "\n",
    "    merged_rows = []\n",
    "\n",
    "    geo_norms = geo_df[\"norm\"].tolist()\n",
    "\n",
    "    for _, row in hq_df.iterrows():\n",
    "        hosp = row[\"HOSPITAL\"]\n",
    "\n",
    "        # ----- Case 1: manual override -----\n",
    "        if hosp in manual:\n",
    "            target_name = manual[hosp]\n",
    "            matches_idx = geo_df[geo_df[\"ENGLISH_NAME\"] == target_name].index\n",
    "            if len(matches_idx) == 0:\n",
    "                print(\"Manual target not found in geo file:\", hosp, \"->\", target_name)\n",
    "                continue\n",
    "            g = geo_df.loc[matches_idx[0]]\n",
    "            merged_rows.append({\n",
    "                **row.to_dict(),\n",
    "                \"ENGLISH_NAME\": g[\"ENGLISH_NAME\"],\n",
    "                \"LONGITUDE\":    g[\"LONGITUDE\"],\n",
    "                \"LATITUDE\":     g[\"LATITUDE\"],\n",
    "                \"ADDRESS\":      g[\"ADDRESS\"],\n",
    "                \"MATCH_METHOD\": \"manual\",\n",
    "                \"MATCH_SCORE\":  None,\n",
    "            })\n",
    "        else:\n",
    "            # ----- Case 2: fuzzy auto-match -----\n",
    "            h_norm = row[\"norm\"]\n",
    "            best = process.extractOne(h_norm, geo_norms, scorer=fuzz.WRatio)\n",
    "            if best is None:\n",
    "                print(\"No fuzzy match found for:\", hosp)\n",
    "                continue\n",
    "\n",
    "            g_norm, score, idx_geo = best\n",
    "            g = geo_df.iloc[idx_geo]\n",
    "\n",
    "            merged_rows.append({\n",
    "                **row.to_dict(),\n",
    "                \"ENGLISH_NAME\": g[\"ENGLISH_NAME\"],\n",
    "                \"LONGITUDE\":    g[\"LONGITUDE\"],\n",
    "                \"LATITUDE\":     g[\"LATITUDE\"],\n",
    "                \"ADDRESS\":      g[\"ADDRESS\"],\n",
    "                \"MATCH_METHOD\": \"auto\",\n",
    "                \"MATCH_SCORE\":  score,\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(merged_rows)\n",
    "\n",
    "merged = build_full_merge(hq, geo, manual_map)\n",
    "\n",
    "print(\"Merged rows:\", len(merged))\n",
    "print(merged[\"MATCH_METHOD\"].value_counts())\n",
    "\n",
    "# -----------------------------------------\n",
    "# 5. Save final merged dataset\n",
    "# -----------------------------------------\n",
    "merged.to_csv(\"hospital_ed_merged_with_geo.csv\", index=False)\n",
    "print(\"Saved hospital_ed_merged_with_geo.csv\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddd989e",
   "metadata": {},
   "source": [
    "Drop Redundant ENGLISH_NAME column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3a182bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_path = \"hospital_ed_merged_with_geo.csv\"\n",
    "df = pd.read_csv(merged_path)\n",
    "\n",
    "# Drop ENGLISH_NAME to avoid redundancy\n",
    "df = df.drop(columns=[\"ENGLISH_NAME\"])\n",
    "\n",
    "# Option 1: overwrite the same file\n",
    "df.to_csv(\"hospital_ed_merged_with_geo.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
